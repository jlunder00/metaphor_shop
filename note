>>> def filter_attrs(attrs):
...     tag_attr_filtered = []
...     for attrs in tag_attr:
...             new_a = {}
...             for k,v in attrs['attrs'].items():
...                     if len(v) > 20 and k == 'href' or k == 'src' or k == 'alt':
...                             new_a[k] = v
...             tag_attr_filtered.append({'text': attrs['text'], 'attrs':new_a})
... 
>>> def filter_attrs(tag_attr):
...     tag_attr_filtered = []
...     for attrs in tag_attr:
...             new_a = {}
...             for k,v in attrs['attrs'].items():
...                     if len(v) > 20 and k == 'href' or k == 'src' or k == 'alt':
...                             new_a[k] = v
...             tag_attr_filtered.append({'text': attrs['text'], 'attrs':new_a})
...     return tag_attr_filtered
... 
>>> tag_attr_filtered_nonempty = [t for t in tag_attr_filtered if len(t.keys()) > 0 and len(t['attrs'].keys()) >0 and len(t['text']) > 25]
>>> def filter_tag_nonempty(tag_attr_filtered, text_len):
#...     return [t for t in tag_attr_filtered if len(t.keys()) > 0 and len(t['attrs'].keys()) >0 and len(t['text']) > text_len]
return [{'text':t['text'].strip('\n').strip(), 'attrs':t['attrs']} for t in tag_attr_filtered if len(t.keys()) > 0 and len(t['attrs'].keys()) >0 and t['text'].find('$') == -1 and (len(t['text'].strip('\n').strip()) > text_min or (len(t['text'].strip('\n').strip()) == text_len_except and ('alt' in t['attrs'].keys() and len(t['attrs']['alt']) > 0))) and ('href' not in t['attrs'].keys() or (t['attrs']['href'].find('/category/') == -1 and t['attrs']['href'].find('search-filter') == -1))]
... 
>>> tag_attr = [{'attrs':t.attrs, 'text':t.text} for t in soup.find_all(custom_selector)]
>>> def get_attr(soup):
...     return [{'attrs':t.attrs, 'text':t.text} for t in soup.find_all(custom_selector)]


def remove_duplicates(l):
...     seen = set()
...     new_l = []
...     for d in l:
...             t = tuple(d.items())
...             if t not in seen:
...                     seen.add(t)
...                     new_l.append(d)
...     return new_l
def remove_duplicates(l, tag):
...     seen = set()
...     new_l = []
...     for d in l:
...             if d[tag] not in seen:
...                     seen.add(d['alt'])
...                     new_l.append(d)
...     return new_l
text2 = [t.text.strip('\n').strip() for t in soup2.find_all(re.compile('.*')) if t.text.strip('\n').strip() != '']
text2_regex = [re.sub('\n\n*', ' ', t) for t in text2]
text2_len_filter_regex = [t for t in text2_regex if (len(t) > 15 or '$' in t) and len(t) < 75]
text2_len_filter_regex_dup_extra_filter = [re.sub('out of 5 stars.*', 'stars', re.sub(r'(\$\d*\.\d\d)(\$\d*\.\d\d)', r'\1', t)) for t in text2_len_filter_regex_dup if "shipped by" not in t and "Free shipping" not in t and ("coupon" not in t and "checkout" not in t)]
all_tags_children_texts = [[t.text for t in tag.find_all(re.compile('.*'))] for tag in all_tags]
>>> matching_urls = [all_tags.attrs['href'] for texts in all_tags_children_texts if list_of_names[0] in texts]

